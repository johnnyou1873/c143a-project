_target_: src.models.speech_module.SpeechModule

# general hyperparameters
lr_start: 0.00025 # adjusted for better performance cer 0.20
lr_end: 0.0000025
n_units: 1024
n_batch: 10000
n_layers: 5
n_classes: 40
n_input_features: 256
dropout: 0.4
gaussian_smooth_width: 2.0
stride_len: 4
kernel_len: 32
bidirectional: False
l2_decay: 0.1
seed: 0

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: ${..lr_start}
  weight_decay: ${..l2_decay}

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: ${trainer.max_epochs}
  eta_min: ${..lr_end}

net:
  _target_: src.models.components.gru_decoder.GRUDecoder
  neural_dim: ${..n_input_features}
  n_classes: ${..n_classes}
  hidden_dim: ${..n_units}
  layer_dim: ${..n_layers}
  nDays: 24
  dropout: ${..dropout}
  strideLen: ${..stride_len}
  kernelLen: ${..kernel_len}
  gaussianSmoothWidth: ${..gaussian_smooth_width}
  bidirectional: ${..bidirectional}

# compile model for faster training with pytorch 2.0
compile: False
