_target_: src.models.ps2s_module.PS2SSpeechModule

# general hyperparameters
lr_start: 0.0003
lr_end: 0.00005
n_units: 1024
n_layers: 5
n_classes: 40
n_input_features: 256
dropout: 0.4
gaussian_smooth_width: 2.0
stride_len: 4
kernel_len: 32
bidirectional: False
l2_decay: 1e-5
seed: 0

# Phoneme-to-phoneme seq2seq guidance
ps2s_weight: 0.5
ps2s_enabled: True
ps2s_model_path: notebooks/data/phoneme_seq2seq.pt
ps2s_device: null
ps2s_max_len: 128
min_base_weight: 0.2
phoneme_labels:
  - <blank>
  - AA
  - AE
  - AH
  - AO
  - AW
  - AY
  - B
  - CH
  - D
  - DH
  - EH
  - ER
  - EY
  - F
  - G
  - HH
  - IH
  - IY
  - JH
  - K
  - L
  - M
  - N
  - NG
  - OW
  - OY
  - P
  - R
  - S
  - SH
  - T
  - TH
  - UH
  - UW
  - V
  - W
  - Y
  - Z
  - ZH
  - <sil>


# 
optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: ${..lr_start}
  weight_decay: ${..l2_decay}

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: ${trainer.max_epochs}
  eta_min: ${..lr_end}

net:
  _target_: src.models.components.gru_decoder.GRUDecoder
  neural_dim: ${..n_input_features}
  n_classes: ${..n_classes}
  hidden_dim: ${..n_units}
  layer_dim: ${..n_layers}
  nDays: 24
  dropout: ${..dropout}
  strideLen: ${..stride_len}
  kernelLen: ${..kernel_len}
  gaussianSmoothWidth: ${..gaussian_smooth_width}
  bidirectional: ${..bidirectional}

# compile model for faster training with pytorch 2.0
compile: false
